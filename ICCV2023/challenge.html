
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <!-- CSS  -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
  <link rel="stylesheet" href="static/css/main.css" media="screen,projection">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
</head>

<body>

<!-- <div class="top-strip"></div> -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="container">
    
    <div class="navbar-header">
      <a class="navbar-brand" href="/"></a>
      <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>

    <div class="navbar-collapse collapse" id="navbar-main">
      <ul class="nav navbar-nav">
        <li><a href="#geonet">GeoNet dataset</a></li>
        <li><a href="#details">Challenge Details</a></li>
        <li><a href="#rules">Challenge Rules</a></li>
        <li><a href="#prizes">Prizes</a></li>
        <li><a href="#contact">Contact</a></li>
      </ul>
    </div>

  </div>
</div>

<div class="container">
  <div class="page-content">
      <p><br /></p>

      <div class="row">
        <div class="col-xs-12">
          <center><h1>GeoNet Challenge Details</h1></center>
          <center><h2>ICCV 2023 Workshop</h2></center>
          <!-- <center>June 25, 2021</center> -->
        </div>
      </div>

<hr />

<div class="row">
    <p>
        The primary objective of the 1st GeoNet challenge is to encourage participants to put forth their ideas and algorithms aimed at addressing the issue of geographical bias by utilizing our recently introduced dataset, GeoNet. The competition consists of two different tracks, each focusing on different settings popular in modern domain adaptation. The unsupervised domain adaptation (UDA) challenge will be evaluated on both the GeoImnet and GeoPlaces datasets, while the universal domain adaptation (UniDA) challenge will be evaluated on the GeoImnet dataset.
    </p>
</div>


<p><br /></p>
<div class="row" id="geonet">
  <div class="col-xs-12">
    <h2><u>Overview of GeoNet dataset</u></h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
        To address the urgent need of evaluating geographical robustness of vision models, we recently created a large-scale dataset called GeoNet which contains images from US and Asia domains covering the tasks of scene recognition (GeoPlaces) and object recognition (GeoImnet). Our benchmark for place recognition, <i>GeoPlaces</i>, is sourced from the popular Places-205 dataset after segregating the images with respect to their geographies. It has more than 700k images in total across 205 categories. Similarly, the benchmark for object classification, <i>GeoImnet</i>, is built using images collected from the WebVision dataset. It consists of over 600k images across USA and Asia domains covering 700 categories. A key facet of this dataset is that the data is collected from the web, which means that label-npoise is a prominent issue, along with cross-geography domain shifts. Please refer to our CVPR 2023 <a href="https://tarun005.github.io/GeoNet/">paper</a> for more details about our dataset. We envision GeoNet to provide a suitable testbed for the community to enable development of geographically robust learning algorithms. Furthermore, we also aim to spur discussion on fairness and inclusivity from the perspective of under-represented geographies. All the participants should use data only from GeoNet for the challenge.
    </p>

    <p style="color:brown;" align="center">
        <i> You can download the dataset  <a href="https://drive.google.com/drive/folders/1x2R1AlCaww7VIrYupCxxGZdkm4nVqFLE?usp=sharing" target="_blank">here</a> </i>. The code for training baseline models on GeoNet is also available at <a href="https://github.com/ViLab-UCSD/GeoNet" target="_blank"> this link</a>
    </p>

  </div>
</div>


<p><br /></p>
<div class="row" id="details">
  <div class="col-xs-12">
    <h2><u>Challenge Details</u></h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <ul>
        <li> <b> Unsupervised Domain Adaptation (UDA): </b> In this challenge, the participants have to devise novel methods for improving performance on target geography which has only unlabeled data during training, by accessing labeled data from a different source geography. For the purpose of this challenge, the source domain is fixed as <i>USA</i> and the target as <i>Asia</i> domains. Therefore, the task is to leverage the labeled images from the USA split from the GeoNet dataset and improve performance on the Asia images, from which several unlabeled images are also provided. The participants cannot use the labels from the Asia images during training. 

            <ul>
                <li><b>Dataset Overview: </b> For the UDA task, the GeoPlaces dataset contains around 178k images from USA domain (labeled data) and 187k images from Asia domain (unlabeled data) from 205 categories. The GeoImnet dataset contains 154k images from USA domain (labeled data) and 68k images from Asia domain (unlabeled data) from 600 categories. In this UDA challenge, participants are <i>not allowed</i> to use the labels from the target domain for training their models.

                <p><br /></p>
                
                <table class="table table-striped" style="margin: auto;">
                <tbody>
                    <tr>
                      <th style="text-align: center;"><strong>Split</strong></th>
                      <th style="text-align: center;"><strong>Data</strong></th>
                    </tr>
                    <tr>
                      <td style="text-align: center;">GeoPlaces</td>
                      <td style="text-align: center;"><a href="https://drive.google.com/file/d/1VeMkGu2kyqRHPSe0Gg7c4qJMdSZUtteS/view?usp=drive_link" style="color: blue;">Link</a></td>
                    </tr>
                    <tr>
                      <td style="text-align: center;">GeoImnet</td>
                      <td style="text-align: center;"><a href="https://drive.google.com/file/d/1XA3g9KuPjKIsVDHahm0T2Wv4_SXL19iV/view?usp=drive_link" style="color: blue;">Link</a></td>
                    </tr>
                    <tr>
                        <td style="text-align: center;">Metadata</td>
                        <td style="text-align: center;"><a href="https://drive.google.com/file/d/17FGPEPztzc3sIW3TUIl8VpsDF9TxuW6R/view?usp=drive_link" style="color: blue;">GeoPlaces</a>, <a href="https://drive.google.com/file/d/1cqBh6PoiSAeruKzzIp2R3FK4jHQHYc0c/view?usp=drive_link" style="color: blue;">GeoImnet</a></td>
                    </tr>
                    <tr>
                        <td style="text-align: center;">Test data</td>
                        <td style="text-align: center;"><a href="" style="color: blue;">To be released!</a></td>
                    </tr>
                </tbody>
                </table>
                  
                </li>

                <p><br /></p>

                <li><b>Evaluation Metric:</b> For the UDA challenge, the models will be ranked based on the average Top-3 accuracy on <i> unseen test set </i> from GeoPlaces and the GeoImnet datasets.  The test images will be publicly released later in the challenge. Owing to the label noise and possible equivalent labels in the dataset, we are using Top-3 accuracy and not Top-1 accuracy for this challenge. </li>

                <p><br /></p>

            </ul>
        
        </li>        

        <li> <b>Universal Domain Adaptation (UniDA):</b> Universal Domain Adaptation (UniDA) facilitates domain adaptation between source and target domains that have few private classes, in addition to shared classes which are common to both. Our proposed GeoNet dataset gives us an unique opportunity to design benchmarks for UniDA such that the private categories from the source and the target are a natural reflection of the presence or absence of these categories in the respective geographical domains. In this challenge, participants will have to use labeled data from a USA domain as the source, and Asia domain as the target, with an additional challenge that the label spaces do not completely overlap. 

            <ul>
                <li><b>Dataset Overview:</b>  The UniDA split of GeoNet is derived solely for GeoImnet. It contains 100k images from USA domain across 200 classes, and more than 34k images from target domain from unknown number of classes. At test-time, the images from Asia domain might be derived from categories unseen during training from either domain, where the task is to correctly classify seen classes while rejecting unseen classes.

                <p><br /></p>
                
                <table class="table table-striped" style="margin: auto;">
                <tbody>
                    <tr>
                      <th style="text-align: center;"><strong>Split</strong></th>
                      <th style="text-align: center;"><strong>Data</strong></th>
                    </tr>
                    <tr>
                      <td style="text-align: center;">GeoImnet-UniDA</td>
                      <td style="text-align: center;"><a href="https://drive.google.com/file/d/10hoPOQN7LpLQwlTh7SPk22iGvJbYjnSK/view?usp=drive_link" style="color: blue;">Link</a></td>
                    </tr>
                    <!-- <tr>
                        <td style="text-align: center;">Metadata</td>
                        <td style="text-align: center;"><a href="https://drive.google.com/file/d/17FGPEPztzc3sIW3TUIl8VpsDF9TxuW6R/view?usp=drive_link" style="color: blue;">GeoPlaces</a>, <a href="https://drive.google.com/file/d/1cqBh6PoiSAeruKzzIp2R3FK4jHQHYc0c/view?usp=drive_link" style="color: blue;">GeoImnet</a></td>
                    </tr> -->
                    <tr>
                        <td style="text-align: center;">Test data</td>
                        <td style="text-align: center;"><a href="" style="color: blue;">To be released!</a></td>
                    </tr>
                </tbody>
                </table>
                
                </li> 

                <p><br /></p>

                <li><b>Evaluation Metric </b> : Following prior work in OpenSet-DA, we use H-acc metric to rank the models for the UniDA task. The H-acc metric is the harmonic mean of the closet-set accuracy (over the seen classes) and the binary open-set accuracy (of rejecting the outlier target test-samples). The H-acc will be evaluated on the unseen test set, which will be publicly released later in the challenge.
                    </li>
                    <p><br /></p>
                    <figure>
                        <img src="static/img/site/formula.png" width="200">
                    </figure>
                 <p><br /></p>
            </ul>
        
        </li>
    </ul>
  </div>
</div>

<p><br /></p>
<div class="row" id="rules">
  <div class="col-xs-12">
    <h2><u>General Guidelines</u></h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <ul>
        <li> Participants can only utilize data from ImageNet-1k for pre-training their models and the provided GeoNet data during training and adaptation. Use of any other kinds of external data is strictly prohibited, which includes the collection or annotation of new data related to the target geographies. If you need any clarifications, please feel free to contact the organizers. </li>

        <li> The winners of the challenge will be invited to present their winning solution during the workshop. Additionally, they will also be required to submit a brief report summarizing their solution, and a working code and trained models for fariness and reproduciblity. </li>

        <li> The participants are allowed to use the metadata (except the labels!) provided along with the GeoNet dataset. However, no metadata beyond the raw images will be provided at test-time to evaluate the models, so the methods should be designed so as to use metadata only during training.  </li>

        <li> The winners will be selected based on the leaderboard performance, with separate winners for the two challenge tracks.   </li>

    </ul>
  </div>
</div>


<p><br /></p>
<div class="row" id="prizes">
  <div class="col-xs-12">
    <h2><u>Leaderboard and Prizes!</u></h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <ul>
        TBD!
    </ul>
  </div>
</div>

<p><br /></p>
<div class="row" id="contact">
  <div class="col-xs-12">
    <h2><u>Contact</u></h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
        For any questions or clarifications about the challenge, please contact the organizers at <b>geonet *dot* robustness *at* gmail.com</b>. 
    </p>
  </div>
</div>

      </div>
    </div>

  </body>
</html>