
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <meta name="keywords" content="iccv, workshop, computer vision, robustness, domain adaptation, transfer learning, machine learning">

  <link rel="shortcut icon" href="static/img/site/favicon.png">

  <title>GeoNet @ICCV2023</title>
  <meta name="description" content="Robust Computer Vision Across Geographies, ICCV 2023 Workshop">

  <!--Open Graph Related Stuff-->
  <meta property="og:title" content="Robust Computer Vision Across Geographies"/>
  <meta property="og:url" content="https://geonet-challenge.github.io"/>
  <meta property="og:description" content="Robust Computer Vision Across Geographies, ICCV 2023 Workshop"/>
  <meta property="og:site_name" content="GeoNet Workshop"/>
  <meta property="og:image" content="https://geonet-challenge.github.io/static/img/site/teaser.png"/>

  <!--Twitter Card Stuff-->
  <meta name="twitter:card" content="summary_large_image"/>
  <meta name="twitter:title" content="Robust Computer Vision Across Geographies Workshop"/>
  <meta name="twitter:image" content="https://geonet-challenge.github.io/static/img/site/teaser.png">
  <meta name="twitter:url" content="https://geonet-challenge.github.io"/>
  <meta name="twitter:description" content="Robust Computer Vision Across Geographies, ICCV 2023 Workshop"/>

  <!-- CSS  -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
  <link rel="stylesheet" href="static/css/main.css" media="screen,projection">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
</head>

  <body>

<!-- <div class="top-strip"></div> -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="container">
    
    <div class="navbar-header">
      <a class="navbar-brand" href="/"></a>
      <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>

    <div class="navbar-collapse collapse" id="navbar-main">
      <ul class="nav navbar-nav">
        <li><a href="#intro">Introduction</a></li>
        <li><a href="challenge.html">Challenge</a></li>
        <li><a href="#dates">Dates</a></li>
        <li><a href="#speakers">Invited Speakers</a></li>
        <li><a href="#schedule">Schedule</a></li>
        <li><a href="#organizers">Organizers</a></li>
        <li><a href="#contact">Contact</a></li>
      </ul>
    </div>

  </div>
</div>

<div class="container">
  <div class="page-content">
      <p><br /></p>

<div class="containerheading">
    <img src="static/img/site/intro.png">
</div>



<hr />


<!-- <br>
  <center>
  <h1 style="color:red"><a href="https://www.youtube.com/watch?v=gyJDGrbLknI">The <b>video recording</b> of this workshop is here!</a></h1>
  </center>
<br> -->

<!-- <div class="row" id="intro">  
    <div>  
    <img src="static/img/site/intro_pic.png" style="width: 100%; height: auto;"/>
  </div>
</div> -->


<!-- <div class="col-xs-6 col-sm-6 col-md-6 col-lg-6"> 
  <img src="static/img/site/a.png">
</div>

<div class="col-xs-6 col-sm-6 col-md-6 col-lg-6"> 
  <img src="static/img/site/b.png">
</div>
 -->


<p><br /></p>
<div class="row" id="intro">
  <div class="col-xs-12">
    <h2><u>Introduction</u></h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p style="color:brown;" align="center">
      <!-- The workshop will be streamed live on zoom. You can join remotely at <a href="https://ucsd.zoom.us/j/99592876816" target="_blank">https://ucsd.zoom.us/j/99592876816.</a> -->
      Due to some technical difficulty, we are unable to livestream the workshop. We deeply apologize for it. We will share the slides of the talk after the workshop. Thank you!
    </p>
    <p>
      This is the first workshop on domain adaptation and robust learning across geographies in computer vision. This workshop aims to unite researchers from across the vision community to foster discussions on the spectrum of challenges posed by geographic bias towards fair and inclusive computer vision. Our primary objective is to facilitate discussions regarding ideas that enable effective deployment of modern AI technology in low and mid-income societies. As part of this workshop, we are also conducting a challenge to benchmark progress in learning geographically robust classification models designed to highlight the emerging open problems in this area. Tapping on the recently introduced large-scale geographic adaptation dataset <b>GeoNet</b>, we host three challenges related to domain adaptation. The workshop consists of keynote talks by experts in the field and short talks regarding methods that successfully address the challenges.
    </p>
  </div>
</div>

<p><br /></p>
<div class="row" id="schedule">
  <div class="col-xs-12">
    <h2><u>Workshop Schedule ( Central European Time )</u></h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
     <table class="table table-striped">
      <tbody>
        <!-- <tr><td>TBD</td><td>TBD</td></tr> -->
        <tr>
          <td></td>
          <td>Welcome and Introduction</td>
          <td>08:30 - 08:40</td>
        </tr>
        <tr>
          <td><i>Keynote Talk 1</i> </td>
          <td><i>Sara Beery: Generalization vs. Specialization </i> </td>
          <td>08:40 - 09:15</td>
        </tr>
        <tr>
          <td><i>Keynote Talk 2</i> </td>
          <td><i>Carl Vondrick: Visual Reasoning via Code Synthesis  </i> </td>
          <td>09:15 - 09:50</td>
        </tr>
        <tr>
          <td><i>Keynote Talk 3</i> </td>
          <td><i> Kristen Grauman: Around the world in 3,000 hours of egocentric video  </i> </td>
          <td>09:50 - 10:25</td>
        </tr>
        <tr>
          <td></td>
          <td>Break</td>
          <td>10:25 - 10:40</td>
        </tr>
        <tr>
          <td></td>
          <td>Oral Presentations by Challenge Winners</td>
          <td>10:40 - 11:15</td>
        </tr>
        <tr>
          <td><i>Keynote Talk 4</i> </td>
          <td><i> Girmaw Tadesse: AI for Impact: Overcoming Challenges with Best Practices. </i> </td>
          <td>11:15 - 11:50</td>
        </tr>
        <tr>
          <td><i>Keynote Talk 5</i> </td>
          <td><i> Judy Hoffman: Addressing Model Robustness by Identifying Bias </i> </td>
          <td>11:50 - 12:25</td>
        </tr>
        <tr>
          <td></td>
          <td>Conclusion</td>
          <td>12:25 - 12:30</td>
        </tr>
      </tbody>
    </table>
  </div>
</div>


<p><br /></p>
<div class="row" id="challenge">
  <div class="col-xs-12">
    <h2><u>1st GeoNet Challenge on Geographical Robustness</u></h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
      The 1st GeoNet challenge contains three tracks, aimed at tackling different problems related to geographical robustness. All the tracks will use data from the recently proposed GeoNet dataset for training and validation. The final scores will be evaluated on a separate unseen test set. More details about the challenge, inlcuding general rules, guidelines and evaluation criterion are presented <a href="challenge.html">on the challenge page</a>.
    </p>
    <!-- <ol>      
      <li>
        <strong>Unsupervised Domain Adaptation</strong>: follows the classical adaptation setting, where the goal is to improve accuracy on an unlabeled target geography using labeled images from a different source geography.
      </li>      
      <li>
        <strong>Universal Domain Adaptation</strong>:, where the aim is to generalize to the target domain with unlabeled samples during training and novel categories at test-time, while using labels from a separate source geography.
      </li>
    </ol> -->

    <!-- <p>
      The challenge leaderboard is online. If you want to join the challenge, see more details here:
    </p>
    <ul>      
      <li>
        <strong><b><a href="http://kaldir.vc.in.tum.de/scanrefer_benchmark/">ScanRefer Challenge</a></b></strong>
      </li>
      <li>
        <strong><b><a href="https://referit3d.github.io/benchmarks.html"> ReferIt3D Challenge</a></b></strong>
      </li>
    </ul> -->
  </div>
</div>


<p>
  <center>
    <b>
      <p style="color:blue" align="center">
        [08/21] We released the test set to the registered participants, and the evaluation portal is live now! <a href="https://eval.ai/web/challenges/challenge-page/2111/leaderboard" target="_blank"> Link to the challenge leaderboard. </a>
      </p>
  <p style="color:brown;" align="center">
    [07/21] Please register for the challenge at this link: <a href="https://forms.gle/zSZA1iaPD3mZxjyn7" target="_blank">https://forms.gle/zSZA1iaPD3mZxjyn7.</a> Note that registering your team is mandatory to participate in the challenge and obtain the test data. 
  </p>
</b>
  <p style="color:brown;" align="center">
    [06/21] Link to the <a href="challenge.html" target="_blank">challenge page.</a>
  </p>
</center>
</p>


<p><br /></p>
<center>
<div class="row" id="dates">
  <div class="col-xs-12">
    <h2><u>Important Challenge Dates</u></h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <table class="table table-striped" style="width: 70%; margin: auto;">
      <tbody>
        <tr>
          <td>Challenge Data Released</td>
          <td> June 15, 2023 </td>
        </tr>
        <tr>
          <td>Challenge Test Set Released</td>
          <td><s>August 10</s>  August 22, 2023</td>
        </tr>
        <tr>
          <td>Submission Portal Open </td>
          <td><s>Aug 15</s>  August 22, 2023 <a href="https://eval.ai/web/challenges/challenge-page/2111/overview" target="_blank" color="blue"> (Link) </a> </td>
        </tr>
        <tr>
          <td>Challenge Submission Deadline</td>
          <td><s>Aug 25</s>  September 5, 2023</td>
        </tr>
        <tr>
          <td>Workshop Date</td>
          <td>Oct 2, 2023 (<span style="background-color:lightcoral;">Day 1 of ICCV 2023</span>)</td>
        </tr>
      </tbody>
    </table>
  </div>
</div>
</center>

<!-- <div class="row"> -->
      <!-- <div class="col-md-24">
        <figure>
          <img src="static/img/site/intro_pic.png" >
          </figure>
      </div> -->
      <!-- <div class="col-md-6">
        <img src="static/img/site/identification.png" height="180px"/>
        <p>Fine-grained 3D Object Identification</p>
      </div> -->
    <!-- </div> -->

<p><br /></p>
<div class="row" id="speakers">
  <div class="col-xs-12">
    <h2><u>Invited Speakers</u></h2>
  </div>
</div>

<p><br /></p>
<div class="row">
  <div class="col-md-2">
    <a href="https://www.cs.utexas.edu/users/grauman/" target="_blank"><img class="people-pic" style="float:left;margin-right:50px;" src="static/img/people/grauman.png" /></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://www.cs.utexas.edu/users/grauman/">Dr. Kristen Grauman</a></b> is a Professor in the Department of Computer Science at the University of Texas at Austin. Her primary research interests are visual recognition and
      visual search and she is well-known for her pioneering works on large-scale image/video retrieval, active learning, active recognition, first-person "egocentric" computer vision, multimodal learning, activity recognition, vision and language, and video summarization. She has also recently led a team of researchers worldwide towards developing a planet-scale egocentric video dataset called Ego4D, which had a significant influence on the landscape of egocentric computer vision.
    </p>
  </div>
</div>

<p><br /></p>

<div class="row">
  <div class="col-md-2">
    <a href="https://faculty.cc.gatech.edu/~judy/" target="_blank"><img class="people-pic" style="float:left;margin-right:50px;" src="static/img/people/hoffman-modified.png"/></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://faculty.cc.gatech.edu/~judy/">Dr. Judy Hoffman</a></b> is an Assistant Professor in the School of Interactive Computing at Georgia Tech, a member of the Machine Learning Center, and a Diversity and Inclusion Fellow. Her research lies at the intersection of computer vision and machine learning with specialization in domain adaptation, transfer learning, adversarial robustness, and algorithmic fairness. She has received numerous awards including NSF CAREER, Google Research Scholar Award (2022), Samsung AI Researcher of the Year Award (2021), NVIDIA female leader in computer vision award (2020), AIMiner top 100 most influential scholars in Machine Learning (2020), MIT EECS Rising Star in 2015, and the NSF Graduate Fellowship. 
      <!-- In addition to her research, she co-founded and continues to advise for Women in Computer Vision, an organization which provides mentorship and travel support for early-career women in the computer vision community.  -->
    </p>
  </div>
</div>
<p><br /></p>

<div class="row">
  <div class="col-md-2">
    <a href="http://www.cs.columbia.edu/~vondrick/" target="_blank"><img class="people-pic" style="float:left;margin-right:50px;" src="static/img/people/vondrick.png" /></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="http://www.cs.columbia.edu/~vondrick/"> Dr. Carl Vondrick </a></b> is an associate professor of computer science at Columbia University. His research focuses on computer vision and machine learning. His research is supported by the NSF, DARPA, Amazon, and Toyota, and his work has appeared on the national news, such as CNN, NPR, the Associated Press and Stephen Colbert's television show. He received the 2021 NSF CAREER Award, the 2021 Toyota Young Faculty Award, and the 2018 Amazon Research Award. Previously, he was a Research Scientist at Google and he received his PhD from MIT in 2017. 
    </p>
  </div>
</div>

<p><br /></p>

<div class="row">
  <div class="col-md-2">
    <a href="https://beerys.github.io/" target="_blank"><img class="people-pic" style="float:left;margin-right:50px;" src="static/img/people/sara.png" /></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://beerys.github.io/">Dr. Sara Beery</a></b> is an assistant professor in the MIT Faculty of Artificial Intelligence and Decision-Making. She was previously a visiting researcher at Google, working on large-scale urban forest monitoring as part of the Auto Arborist project. She received her PhD in Computing and Mathematical Sciences at Caltech in 2022, where she was advised by Pietro Perona and awarded the Amori Doctoral Prize for her thesis. Her research focuses on building computer vision methods that enable global-scale environmental and biodiversity monitoring across data modalities, tackling real-world challenges including geospatial and temporal domain shift, learning from imperfect data, fine-grained categories, and long-tailed distributions. She partners with industry, nongovernmental organizations, and government agencies to deploy her methods in the wild worldwide. She works toward increasing the diversity and accessibility of academic research in artificial intelligence through interdisciplinary capacity building and education, and has founded the AI for Conservation slack community, serves as the Biodiversity Community Lead for Climate Change AI, and founded and directs the Summer Workshop on Computer Vision Methods for Ecology.
    </p>
  </div>
</div>

<p><br /></p>

<div class="row">
  <div class="col-md-2">
    <a href="https://www.microsoft.com/en-us/research/people/gtadesse/" target="_blank"><img class="people-pic" style="float:left;margin-right:50px;" src="static/img/people/tadesse.png" /></a>
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://www.microsoft.com/en-us/research/people/gtadesse/"> Dr. Girmaw Abebe Tadesse </a></b> is a Principal Research Scientist and Manager at Microsoft AI for Good Research Lab which aims to develop AI solutions for critical problems across sectors including agriculture, healthcare, biodiversity, etc. Previously at IBM Research Africa, Girmaw led multiple projects in trustworthy AI including evaluation of generative models, representation analysis in academic materials and data-driven insight extraction from public healthy surveys, with active collaborations with external institutions such as Bill & Melinda Gates Foundation, Stanford University, Oxford University and Harvard University. He has interned/worked in various research groups across Europe, including the UPC-BarcelonaTech (Spain), KU Leuven (Belgium), and INESC-ID (Portugal). 
    </p>
  </div>
</div>

<p><br /></p>
</div>

<p><br /></p>

<div class="row" id="organizers">
  <div class="col-xs-12">
    <h2>Organizers</h2>
  </div>
</div>

<div class="row">
  <div class="col-xs-3">
    <a href="https://tarun005.github.io/" target="_blank">
      <img class="people-pic" src="static/img/people/tarun.png" />
    </a>
    <div class="people-name">
      <a href="https://tarun005.github.io/" target="_blank">Tarun Kalluri</a>
      <h6>UC San Diego</h6>
    </div>
  </div>

  <div class="col-xs-3">
    <a href="https://yuyingyeh.github.io/" target="_blank">
      <img class="people-pic" src="static/img/people/YuYing.png" />
    </a>
    <div class="people-name">
      <a href="https://yuyingyeh.github.io/" target="_blank">Yu-Ying Yeh</a>
      <h6>UC San Diego</h6>
    </div>
  </div>

  <div class="col-xs-3">
    <a href="https://lear.inrialpes.fr/people/alahari/" target="_blank">
      <img class="people-pic" src="static/img/people/karteek.png" />
    </a>
    <div class="people-name">
      <a href="https://lear.inrialpes.fr/people/alahari/" target="_blank">Karteek Alahari</a>
      <h6>Inria Grenoble</h6>
    </div>
  </div>

  <div class="col-xs-3">
    <a href="https://cseweb.ucsd.edu//~mkchandraker/" target="_blank">
      <img class="people-pic" src="static/img/people/manmohan.png" />
    </a>
    <div class="people-name">
      <a href="https://cseweb.ucsd.edu//~mkchandraker/" target="_blank">Manmohan Chandraker</a>
      <h6>UC San Diego</h6>
    </div>
  </div>

</div>

<div class="row" id="contact">
  <div class="col-xs-12">
    <h2>Contact</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
      To contact the organizers please use <b>geonet *dot* robustness *at* gmail.com</b>
    </p>
  </div>
</div>
<p><br /></p>

<hr />

<div class="row">
  <div class="col-xs-12">
    <h2>Acknowledgments</h2>
  </div>
</div>
<p><a name="/acknowledgements"></a></p>
<div class="row">
  <div class="col-xs-12">
    <p>
      Thanks to <span style="color:#1a1aff;font-weight:400;"> <a href="https://languagefor3dscenes.github.io/ECCV2022/">Language for 3D scenes workshop</a></span> for the webpage format.
    </p>
  </div>
</div>

      </div>
    </div>

  </body>
</html>